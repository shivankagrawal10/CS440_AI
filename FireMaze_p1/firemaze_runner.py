import numpy as np
import random
import heapq
import math
import firemaze as mg
import constants
import copy
import matplotlib.pyplot as plt

#Experiment Class has framework to test the firemaze by creating an instance of a firemaze object, updating the fire
#in each time step, and taking in user input for the type of strategy to use

class experiment:
    #Experiment constructor
    #@param takes in probability density of barrier (p), flammability quotient (q), start coordinate, end coordinate, strategy, and optional seed
    # Strategy: {1:(Astar search 1 time), 2:(Astar search at each step), 3:(Marco Polo search with large steps), 4:(Marco Polo Probability with large steps) 
    def __init__(self, dim : int, p : float, q : float, start : (int, int), end : (int, int), strategy: int, seed=-1):
        self.seed = seed
        if(seed>=0):
            self.rg=random.Random(seed)
            self.maze = mg.maze(dim, p, q,seed=self.rg.randint(0,100))
        else:
            self.rg=random.Random()
            self.maze = mg.maze(dim, p, q)
        #Creating seed object to ensure we can recreate mazes and fire scenarios when testing
        self.q = q
        self.start = start
        self.end = end
        y, x = start
        self.agent = (y, x)
        self.maze.grid[y][x] = constants.AGENT
        self.strategy = strategy
        self.switch = False
        self.neighbor_prob={}
        

    def run(self):
        if not self.maze.fireloc:
                self.start_fire()
        plan = []
        while self.agent != self.end:
            plan = self.advance_agent(self.strategy, plan)
            if not plan:
                break
            new_grid = self.advance_fire()
            y, x = self.agent
            if new_grid[y][x] == constants.FIRE:
                break
            self.maze.grid = new_grid
        if self.agent == self.end:
            return True
        else:
            return False

    def man_run(self,animate):
        if not self.maze.fireloc:
            self.start_fire()
        plan = []
        while self.agent != self.end:
            if(animate):
                if(animate==1):
                    self.maze.maze_visualize(self.agent,self.maze.grid,0)
                else:
                    self.maze.maze_visualize(self.agent,self.maze.grid,2)
            #input("Press any key to continue") #optional if want to see maze for longer
            plan = self.generate_plan(self.strategy, plan)
            if not plan:
                break
            plan = self.execute_plan(self.strategy, plan)
        if(animate):
            if(animate==1):
                self.maze.maze_visualize(self.agent,self.maze.grid,1)
            else:
                self.maze.maze_visualize(self.agent,self.maze.grid,3)
        if self.agent == self.end:
            return True
        else:
            return False

    #Generates a path the agent should follow based on selected strategy 
    #if not a valid strategy or agent on fire then will return an empty plan
    #@return plan (list object)
    def generate_plan(self, strategy, plan):
        if self.maze.grid[self.agent[0]][self.agent[1]] == constants.FIRE:
            return []
        if strategy == constants.STRATEGY_1 and not plan:
            plan, _ = self.maze.Astar(self.agent, self.end)
        elif strategy == constants.STRATEGY_2:
            plan, _ = self.maze.Astar(self.agent, self.end)
        elif strategy == constants.STRATEGY_3:
            plan, _ = self.maze.Marco_Polo(self.agent, self.end)
        elif strategy == constants.STRATEGY_4:
            plan, _ =  self.maze.Marco_Polo(self.agent, self.end)
        elif strategy == constants.STRATEGY_5:
            plan, _ = self.maze.Marco_Polo_Prob(self.agent, self.end)
        return plan

    #Responsible for running the plan generated by the search strategy
    #modularizing the running from planning enables us to experiment with number of steps taken before searching again
    def execute_plan(self, strategy, plan):
        times = 0
        if strategy == constants.STRATEGY_1:
            times = len(plan) - 1
        elif strategy == constants.STRATEGY_2 or strategy == constants.STRATEGY_5:
            times = 1
        elif strategy == constants.STRATEGY_3:
            times = max(int((self.maze.dist_to_nearest_fire(plan[0]))/2),1)
        elif strategy == constants.STRATEGY_4:
            times = int((self.maze.dist_to_nearest_fire(plan[0]))/2)
            if times < 1:
                #print("Switching")
                #self.maze.maze_visualize(self.agent,self.maze.grid,0)
                best_prob , best_first_step = self.simulation()
                #self.maze.maze_visualize(self.agent,self.maze.grid,0)
                plan,_ = self.maze.Marco_Polo_Prob(self.agent, self.end,self.neighbor_prob)
                self.neighbor_prob={}
                times=1
        '''
        elif strategy == constants.STRATEGY_5:
            times = int((self.maze.dist_to_nearest_fire(plan[0]))/2)
            if times <= 1:
                #print("Switching")
                #best_prob , best_first_step = self.simulation()
                plan,_ = self.maze.Marco_Polo_Prob(self.agent, self.end,self.neighbor_prob)
                times=1
        '''
        for i in range(times):
            if self.agent == self.end: 
                plan = []
                break
            if plan:
                curr = plan.pop(0)
                y, x = plan[0]
                if self.maze.grid[y][x] == constants.FIRE:
                    plan = []
                    break
                else:
                    old_y, old_x = self.agent
                    new_y, new_x = self.agent = plan[0]
                    self.maze.grid[old_y][old_x] = constants.OPEN
                    self.maze.grid[new_y][new_x] = constants.AGENT
            else:
                break
            new_grid = self.advance_fire()
            y, x = self.agent
            self.maze.grid = new_grid
            if new_grid[y][x] == constants.FIRE:
                    plan = []
                    break
        return plan


    def advance_agent(self, strategy, plan):
        if strategy == constants.STRATEGY_1 and not plan:
            plan, _ = self.maze.Astar(self.agent, self.end)
        elif strategy == constants.STRATEGY_2:
            plan, _ = self.maze.Astar(self.agent, self.end)
        elif strategy == constants.STRATEGY_3:
            plan, _ = self.maze.Marco_Polo(self.agent,self.end)
        elif strategy == constants.STRATEGY_4:
            plan, _ = self.maze.Marco_Polo(self.agent,self.end)
        if plan:
            plan.pop(0)
            y, x = plan[0]
            if self.maze.grid[y][x] == constants.FIRE:
                plan = []
            else:
                old_y, old_x = self.agent
                new_y, new_x = self.agent = plan[0]
                self.maze.grid[old_y][old_x] = constants.OPEN
                self.maze.grid[new_y][new_x] = constants.AGENT
        return plan

    def advance_fire(self):
        clone = self.maze.clone_grid()
        for i in range(self.maze.dim):
            for j in range(self.maze.dim):
                if clone[i][j] != constants.FIRE and clone[i][j] != constants.BLOCKED:
                    prob = self.maze.get_fire_prob((i, j))
                    if prob != 0 and self.rg.random() <= prob:
                        clone[i][j] = constants.FIRE
                        self.maze.fireloc.append((i,j))
        return clone

    def start_fire(self):
        open_cells = []
        for i in range(self.maze.dim):
            for j in range(self.maze.dim):
                if self.maze.grid[i][j] == constants.OPEN:
                    open_cells.append((i, j))
        y, x = self.rg.choice(open_cells)
        self.maze.grid[y][x] = constants.FIRE
        self.maze.fireloc.append((y,x))
        return ((y,x))

    def simulation(self):
        best = (0, self.agent)
        neighbors = self.maze.get_neighbors(self.agent,self.maze.is_open)
        neighbors = list(neighbors)
        for n in neighbors:
            p = self.get_probability(n)
            self.neighbor_prob[n]=p
            if p > best[0]:
                best = (p, n)
        return best

    def get_probability(self, start: (int, int)):
        success = 0
        times=5
        for i in range(times):
            sim = experiment(self.maze.dim,self.maze.p,self.q,
                             start,self.end,constants.STRATEGY_3)
            sim.maze.grid = self.maze.clone_grid()
            sim.maze.fireloc = self.maze.fireloc
            sim.agent = start
            sim.advance_fire()
            if sim.man_run(2):
                success += 1
        return float(success / times)


    def Sims(self):
        neighbors = self.maze.get_neighbors(self.agent, self.maze.is_open)
        forks = []
        i = 0
        while True:
            try:
                neighbor = next(neighbors)
                forks.append(experiment(self.maze.dim, self.maze.p, self.q, self.agent, self.end, constants.STRATEGY_2))
                forks[i].maze.grid = self.maze.clone_grid()
                old_y, old_x = forks[i].agent
                new_y, new_x = neighbor
                forks[i].maze.grid[old_y][old_x] = constants.OPEN
                forks[i].maze.grid[new_y][new_x] = constants.AGENT
                forks[i].agent = neighbor
                forks[i].start = neighbor
                forks[i].maze.fireloc = self.maze.fireloc #THIS WILL NEED TO CHANGE IF STRAT 3
                forks[i].switch = True
                i = i + 1
            except StopIteration:
                break
        success_rates = [0, 0, 0, 0]
        for i, fork in enumerate(forks):
            maze_start_state = fork.maze.clone_grid()
            agent_start_state = fork.agent
            for j in range(21):
                success_rates[i] += fork.man_run()
                fork.maze.grid = maze_start_state.clone_grid()
                fork.agent = agent_start_state
        highest_sr = 0
        highest_sr_index = 0
        for i, sr in enumerate(success_rates):
            if sr >= highest_sr:
                highest_sr = sr
                highest_sr_index = i
        return forks[highest_sr_index].maze.Astar(forks[highest_sr_index].start, self.end)

dim=15
random.seed(dim)
for i in range(3):   
    exp = experiment(dim, .2 , .2, (0, 0), (dim-1, dim-1), 4,seed=random.randint(0,10))
    if i==2:
        exp.man_run(1)
